{
  final StringBuilder outputStr=new StringBuilder();
  final List<String> sentences=sentenceTokenizer.tokenize(input);
  for (  final String sentence : sentences) {
    final List<String> tokens=tokenizer.tokenize(sentence);
    final List<String> noWhitespaceTokens=getNoWhitespaceTokens(tokens);
    final List<AnalyzedTokenReadings> aTokens=tagger.tag(noWhitespaceTokens);
    final AnalyzedTokenReadings[] tokenArray=new AnalyzedTokenReadings[tokens.size() + 1];
    final AnalyzedToken[] startTokenArray=new AnalyzedToken[1];
    int toArrayCount=0;
    final AnalyzedToken sentenceStartToken=new AnalyzedToken("",JLanguageTool.SENTENCE_START_TAGNAME,null);
    startTokenArray[0]=sentenceStartToken;
    tokenArray[toArrayCount++]=new AnalyzedTokenReadings(startTokenArray,0);
    int startPos=0;
    int noWhitespaceCount=0;
    for (    final String tokenStr : tokens) {
      AnalyzedTokenReadings posTag=null;
      if (isWord(tokenStr)) {
        posTag=aTokens.get(noWhitespaceCount);
        posTag.setStartPos(startPos);
        noWhitespaceCount++;
      }
 else {
        posTag=tagger.createNullToken(tokenStr,startPos);
      }
      tokenArray[toArrayCount++]=posTag;
      startPos+=tokenStr.length();
    }
    AnalyzedSentence finalSentence=new AnalyzedSentence(tokenArray);
    finalSentence=disambiguator.disambiguate(finalSentence);
    final AnalyzedTokenReadings[] output=finalSentence.getTokens();
    for (int i=0; i < output.length; i++) {
      final AnalyzedTokenReadings tokenReadings=output[i];
      final List<String> readings=getAsStrings(tokenReadings);
      outputStr.append(StringTools.listToString(readings,"|"));
      if (i < output.length - 1) {
        outputStr.append(' ');
      }
    }
  }
  assertEquals(expected,outputStr.toString());
}
