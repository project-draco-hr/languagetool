{
  if (allFeatsIn && equivalencesMatched.isEmpty()) {
    return false;
  }
  if (uFeatures == null) {
    return false;
  }
  unificationFeats=uFeatures;
  boolean unified=true;
  List<String> types;
  if (allFeatsIn) {
    unified=checkNext(aToken,uFeatures);
  }
 else {
    while (equivalencesMatched.size() <= tokCnt) {
      equivalencesMatched.add(new ConcurrentHashMap<String,Set<String>>());
    }
    for (    final Map.Entry<String,List<String>> feat : uFeatures.entrySet()) {
      types=feat.getValue();
      if (types == null || types.isEmpty()) {
        types=equivalenceFeatures.get(feat.getKey());
      }
      for (      final String typeName : types) {
        final Element testElem=equivalenceTypes.get(new EquivalenceTypeLocator(feat.getKey(),typeName));
        if (testElem == null) {
          return false;
        }
        if (testElem.isMatched(aToken)) {
          if (!equivalencesMatched.get(tokCnt).containsKey(feat.getKey())) {
            final Set<String> typeSet=new HashSet<>();
            typeSet.add(typeName);
            equivalencesMatched.get(tokCnt).put(feat.getKey(),typeSet);
          }
 else {
            equivalencesMatched.get(tokCnt).get(feat.getKey()).add(typeName);
          }
        }
      }
      unified=equivalencesMatched.get(tokCnt).containsKey(feat.getKey());
      if (!unified) {
        break;
      }
    }
    if (unified) {
      if (tokCnt == 0 || tokSequence.isEmpty()) {
        tokSequence.add(new AnalyzedTokenReadings(aToken,0));
        List<Map<String,Set<String>>> equivList=new ArrayList<>();
        equivList.add(equivalencesMatched.get(tokCnt));
        tokSequenceEquivalences.add(equivList);
      }
 else {
        tokSequence.get(0).addReading(aToken);
        tokSequenceEquivalences.get(0).add(equivalencesMatched.get(tokCnt));
      }
      tokCnt++;
    }
  }
  return unified;
}
