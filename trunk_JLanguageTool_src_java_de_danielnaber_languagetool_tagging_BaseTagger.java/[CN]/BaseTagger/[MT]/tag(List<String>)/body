{
  String[] taggerTokens;
  List<AnalyzedTokenReadings> tokenReadings=new ArrayList<AnalyzedTokenReadings>();
  int pos=0;
  if (morfologik == null) {
    setFileName();
    morfologik=new Lametyzator();
  }
  for (  String word : sentenceTokens) {
    final List<AnalyzedToken> l=new ArrayList<AnalyzedToken>();
    String[] lowerTaggerTokens=null;
    taggerTokens=morfologik.stemAndForm(word);
    if (!word.equals(word.toLowerCase(conversionLocale))) {
      lowerTaggerTokens=morfologik.stemAndForm(word.toLowerCase(conversionLocale));
    }
    addTokens(word,taggerTokens,l,pos);
    addTokens(word,lowerTaggerTokens,l,pos);
    if (lowerTaggerTokens == null && taggerTokens == null) {
      if (word.equals(word.toLowerCase(conversionLocale))) {
        String[] upperTaggerTokens=null;
        upperTaggerTokens=morfologik.stemAndForm(StringTools.uppercaseFirstChar(word));
        if (upperTaggerTokens != null) {
          addTokens(word,upperTaggerTokens,l,pos);
        }
 else {
          l.add(new AnalyzedToken(word,null,pos));
        }
      }
 else {
        l.add(new AnalyzedToken(word,null,pos));
      }
    }
    pos+=word.length();
    tokenReadings.add(new AnalyzedTokenReadings(l.toArray(new AnalyzedToken[l.size()])));
  }
  return tokenReadings;
}
