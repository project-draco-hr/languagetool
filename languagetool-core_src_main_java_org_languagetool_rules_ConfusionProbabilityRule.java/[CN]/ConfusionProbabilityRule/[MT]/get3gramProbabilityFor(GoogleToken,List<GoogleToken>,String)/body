{
  List<GoogleToken> newTokens=getGoogleTokens(term);
  Probability ngram3Left;
  Probability ngram3Middle;
  Probability ngram3Right;
  if (newTokens.size() == 1) {
    ngram3Left=getPseudoProbability(getContext(token,tokens,term,0,2));
    ngram3Middle=getPseudoProbability(getContext(token,tokens,term,1,1));
    ngram3Right=getPseudoProbability(getContext(token,tokens,term,2,0));
  }
 else   if (newTokens.size() == 2) {
    ngram3Left=getPseudoProbability(getContext(token,tokens,newTokens,0,1));
    ngram3Right=getPseudoProbability(getContext(token,tokens,newTokens,1,0));
    ngram3Middle=new Probability((ngram3Left.prob + ngram3Right.prob) / 2,1.0f);
  }
 else {
    throw new RuntimeException("Words that consists of more than 2 tokens (according to Google tokenization) are not supported yet: " + term + " -> "+ newTokens);
  }
  if (ngram3Left.coverage < MIN_COVERAGE && ngram3Middle.coverage < MIN_COVERAGE && ngram3Right.coverage < MIN_COVERAGE) {
    debug("  Min coverage of %.2f not reached: %.2f, %.2f, %.2f, assuming p=0\n",MIN_COVERAGE,ngram3Left.coverage,ngram3Middle.coverage,ngram3Right.coverage);
    return 0.0;
  }
 else {
    return ngram3Left.prob * ngram3Middle.prob * ngram3Right.prob;
  }
}
