{
  if (args.length < 5 || args.length > 6) {
    System.err.println("Usage: " + ConfusionRuleEvaluator.class.getSimpleName() + " <token> <homophoneToken> <langCode> <languageModelTopDir> <wikipediaXml|tatoebaFile|plainTextFile|dir>...");
    System.err.println("   <languageModelTopDir> is a directory with sub-directories like 'en' which then again contain '1grams',");
    System.err.println("                      '2grams', and '3grams' sub directories with Lucene indexes");
    System.err.println("                      See http://wiki.languagetool.org/finding-errors-using-n-gram-data");
    System.err.println("   <wikipediaXml|tatoebaFile|plainTextFile|dir> either a Wikipedia XML dump, or a Tatoeba file, or");
    System.err.println("                      a plain text file with one sentence per line, or a directory with");
    System.err.println("                      example sentences (where <word>.txt contains only the sentences for <word>).");
    System.err.println("                      You can specify both a Wikipedia file and a Tatoeba file.");
    System.exit(1);
  }
  long startTime=System.currentTimeMillis();
  String token=args[0];
  String homophoneToken=args[1];
  String langCode=args[2];
  Language lang;
  if ("en".equals(langCode)) {
    lang=new EnglishLight();
  }
 else {
    lang=Languages.getLanguageForShortName(langCode);
  }
  LanguageModel languageModel=new LuceneLanguageModel(new File(args[3],lang.getShortName()));
  List<String> inputsFiles=new ArrayList<>();
  inputsFiles.add(args[4]);
  if (args.length >= 6) {
    inputsFiles.add(args[5]);
  }
  ConfusionRuleEvaluator generator=new ConfusionRuleEvaluator(lang,languageModel,CASE_SENSITIVE);
  generator.run(inputsFiles,token,homophoneToken,MAX_SENTENCES,EVAL_FACTORS);
  long endTime=System.currentTimeMillis();
  System.out.println("\nTime: " + (endTime - startTime) + "ms");
}
