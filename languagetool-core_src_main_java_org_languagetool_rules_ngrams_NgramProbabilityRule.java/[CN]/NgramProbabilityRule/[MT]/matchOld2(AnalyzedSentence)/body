{
  String text=sentence.getText();
  List<GoogleToken> tokens=GoogleToken.getGoogleTokens(text,true,getGoogleStyleWordTokenizer());
  List<RuleMatch> matches=new ArrayList<>();
  GoogleToken prevPrevToken=null;
  GoogleToken prevToken=null;
  int i=0;
  for (  GoogleToken googleToken : tokens) {
    String token=googleToken.token;
    if (prevPrevToken != null && prevToken != null) {
      if (i < tokens.size() - 1) {
        GoogleToken next=tokens.get(i + 1);
        long occurrences=lm.getCount(prevToken.token,token,next.token);
        String ngram=prevToken + " " + token+ " "+ next.token;
        debug("lookup: " + ngram + " => "+ occurrences+ "\n");
        if (occurrences < MIN_OKAY_OCCURRENCES) {
          String message="ngram '" + ngram + "' rarely occurs in ngram reference corpus (occurrences: "+ occurrences+ ")";
          RuleMatch match=new RuleMatch(this,prevToken.startPos,next.endPos,message);
          matches.add(match);
        }
      }
    }
    prevPrevToken=prevToken;
    prevToken=googleToken;
    i++;
  }
  return matches.toArray(new RuleMatch[matches.size()]);
}
