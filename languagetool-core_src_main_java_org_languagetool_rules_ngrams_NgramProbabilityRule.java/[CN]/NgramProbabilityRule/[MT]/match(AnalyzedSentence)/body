{
  String text=sentence.getText();
  List<GoogleToken> tokens=GoogleToken.getGoogleTokens(text,true,getWordTokenizer());
  List<RuleMatch> matches=new ArrayList<>();
  GoogleToken prevPrevToken=null;
  GoogleToken prevToken=null;
  for (  GoogleToken googleToken : tokens) {
    String token=googleToken.token;
    if (prevPrevToken != null && prevToken != null) {
      long occurrences=lm.getCount(prevPrevToken.token,prevToken.token,token);
      debug("lookup: " + prevPrevToken + " "+ prevToken+ " "+ token+ " => "+ occurrences+ "\n");
      if (occurrences < MIN_OKAY_OCCURRENCES) {
        String message="ngram rarely occurs in ngram reference corpus (occurrences: " + occurrences + ")";
        RuleMatch match=new RuleMatch(this,prevPrevToken.startPos,googleToken.endPos,message);
        matches.add(match);
      }
    }
    prevPrevToken=prevToken;
    prevToken=googleToken;
  }
  return matches.toArray(new RuleMatch[matches.size()]);
}
