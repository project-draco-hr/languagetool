{
  String text=sentence.getText();
  List<GoogleToken> tokens=GoogleToken.getGoogleTokens(text,true,getGoogleStyleWordTokenizer());
  List<RuleMatch> matches=new ArrayList<>();
  GoogleToken prevPrevToken=null;
  GoogleToken prevToken=null;
  int i=0;
  for (  GoogleToken googleToken : tokens) {
    String token=googleToken.token;
    if (prevPrevToken != null && prevToken != null) {
      if (i < tokens.size() - 1) {
        GoogleToken next=tokens.get(i + 1);
        Probability p=getPseudoProbability(Arrays.asList(prevToken.token,token,next.token));
        String ngram=prevToken + " " + token+ " "+ next.token;
        double prob=p.getProb();
        if (prob < minProbability) {
          long occurrences=lm.getCount(prevToken.token,token,next.token);
          String message="ngram '" + ngram + "' rarely occurs in ngram reference corpus (occurrences: "+ occurrences+ ")";
          RuleMatch match=new RuleMatch(this,prevToken.startPos,next.endPos,message);
          matches.add(match);
        }
      }
    }
    prevPrevToken=prevToken;
    prevToken=googleToken;
    i++;
  }
  return matches.toArray(new RuleMatch[matches.size()]);
}
