{
  String[] taggerTokens;
  final List<AnalyzedTokenReadings> tokenReadings=new ArrayList<AnalyzedTokenReadings>();
  int pos=0;
  if (morfologik == null) {
    setFileName();
    morfologik=new Lametyzator();
  }
  for (  final String word : sentenceTokens) {
    final List<AnalyzedToken> l=new ArrayList<AnalyzedToken>();
    taggerTokens=morfologik.stemAndForm(_hideDiacritics(word.toLowerCase()));
    if (taggerTokens != null) {
      int i=0;
      while (i < taggerTokens.length) {
        final String lemma=_revealDiacritics(taggerTokens[i]);
        final String[] tagsArr=taggerTokens[i + 1].split("\\+");
        for (        final String currTag : tagsArr) {
          l.add(new AnalyzedToken(word,currTag,lemma,pos));
        }
        i=i + 2;
      }
    }
    if (taggerTokens == null) {
      l.add(new AnalyzedToken(word,null,pos));
    }
    pos+=word.length();
    tokenReadings.add(new AnalyzedTokenReadings(l.toArray(new AnalyzedToken[l.size()])));
  }
  return tokenReadings;
}
