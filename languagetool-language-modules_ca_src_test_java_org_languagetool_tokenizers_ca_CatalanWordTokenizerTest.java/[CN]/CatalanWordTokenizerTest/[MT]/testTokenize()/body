{
  CatalanWordTokenizer wordTokenizer=new CatalanWordTokenizer();
  List<String> tokens;
  tokens=wordTokenizer.tokenize("L'\"ala bastarda\".");
  assertEquals(tokens.size(),7);
  assertEquals("[L', \", ala,  , bastarda, \", .]",tokens.toString());
  tokens=wordTokenizer.tokenize("Emporta-te'ls a l'observatori dels mars");
  assertEquals(tokens.size(),13);
  assertEquals("[Emporta, -te, 'ls,  , a,  , l', observatori,  , de, ls,  , mars]",tokens.toString());
  tokens=wordTokenizer.tokenize("Emporta-te???ls a l???observatori dels mars");
  assertEquals(tokens.size(),13);
  assertEquals("[Emporta, -te, ???ls,  , a,  , l???, observatori,  , de, ls,  , mars]",tokens.toString());
  tokens=wordTokenizer.tokenize("???El tren Barcelona-Val??ncia???");
  assertEquals(tokens.size(),9);
  assertEquals("[???, El,  , tren,  , Barcelona, -, Val??ncia, ???]",tokens.toString());
  tokens=wordTokenizer.tokenize("El tren Barcelona-Val??ncia");
  assertEquals(tokens.size(),7);
  assertEquals("[El,  , tren,  , Barcelona, -, Val??ncia]",tokens.toString());
  tokens=wordTokenizer.tokenize("No acabava d???entendre???l b??");
  assertEquals(tokens.size(),9);
  assertEquals("[No,  , acabava,  , d???, entendre, ???l,  , b??]",tokens.toString());
  tokens=wordTokenizer.tokenize("N'hi ha vint-i-quatre");
  assertEquals(tokens.size(),6);
  assertEquals("[N', hi,  , ha,  , vint-i-quatre]",tokens.toString());
  tokens=wordTokenizer.tokenize("Mont-ras");
  assertEquals(tokens.size(),1);
  assertEquals("[Mont-ras]",tokens.toString());
  tokens=wordTokenizer.tokenize("??s d'1 km.");
  assertEquals(tokens.size(),7);
  assertEquals("[??s,  , d', 1,  , km, .]",tokens.toString());
  tokens=wordTokenizer.tokenize("??s d'1,5 km.");
  assertEquals(tokens.size(),7);
  assertEquals("[??s,  , d', 1,5,  , km, .]",tokens.toString());
  tokens=wordTokenizer.tokenize("??s d'5 km.");
  assertEquals(tokens.size(),7);
  assertEquals("[??s,  , d', 5,  , km, .]",tokens.toString());
  tokens=wordTokenizer.tokenize("la direcci?? E-SE");
  assertEquals(tokens.size(),7);
  assertEquals("[la,  , direcci??,  , E, -, SE]",tokens.toString());
  tokens=wordTokenizer.tokenize("la direcci?? NW-SE");
  assertEquals(tokens.size(),7);
  assertEquals("[la,  , direcci??,  , NW, -, SE]",tokens.toString());
  tokens=wordTokenizer.tokenize("Se'n d??na vergonya");
  assertEquals(tokens.size(),6);
  assertEquals("[Se, 'n,  , d??na,  , vergonya]",tokens.toString());
  tokens=wordTokenizer.tokenize("Em??lia-Romanya");
  assertEquals(tokens.size(),3);
  assertEquals("[Em??lia, -, Romanya]",tokens.toString());
  tokens=wordTokenizer.tokenize("L'Em??lia-Romanya");
  assertEquals(tokens.size(),4);
  assertEquals("[L', Em??lia, -, Romanya]",tokens.toString());
  tokens=wordTokenizer.tokenize("col??laboraci??");
  assertEquals(tokens.size(),1);
  tokens=wordTokenizer.tokenize("col.laboraci??");
  assertEquals(tokens.size(),1);
  tokens=wordTokenizer.tokenize("col???laboraci??");
  assertEquals(tokens.size(),1);
  tokens=wordTokenizer.tokenize("col??Laboraci??");
  assertEquals(tokens.size(),1);
  tokens=wordTokenizer.tokenize("Sud-Est");
  assertEquals(tokens.size(),3);
  assertEquals("[Sud, -, Est]",tokens.toString());
  tokens=wordTokenizer.tokenize("Sud-est");
  assertEquals(tokens.size(),1);
}
