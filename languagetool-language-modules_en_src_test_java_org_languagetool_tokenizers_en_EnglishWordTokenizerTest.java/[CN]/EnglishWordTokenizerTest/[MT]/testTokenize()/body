{
  final EnglishWordTokenizer wordTokenizer=new EnglishWordTokenizer();
  final List<String> tokens=wordTokenizer.tokenize("This is\u00A0a test");
  assertEquals(tokens.size(),7);
  assertEquals("[This,  , is, \u00A0, a,  , test]",tokens.toString());
  final List<String> tokens2=wordTokenizer.tokenize("This\rbreaks");
  assertEquals(3,tokens2.size());
  assertEquals("[This, \r, breaks]",tokens2.toString());
  final List<String> tokens3=wordTokenizer.tokenize("Now this is-really!-a test.");
  assertEquals(tokens3.size(),10);
  assertEquals("[Now,  , this,  , is-really, !, -a,  , test, .]",tokens3.toString());
  final List<String> tokens4=wordTokenizer.tokenize("Now this is- really!- a test.");
  assertEquals(tokens4.size(),15);
  assertEquals("[Now,  , this,  , is, -,  , really, !, -,  , a,  , test, .]",tokens4.toString());
  final List<String> tokens5=wordTokenizer.tokenize("Now this is???really!???a test.");
  assertEquals(tokens5.size(),13);
  assertEquals("[Now,  , this,  , is, ???, really, !, ???, a,  , test, .]",tokens5.toString());
}
