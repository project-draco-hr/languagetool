{
  final List<RuleMatch> ruleMatches=new ArrayList<RuleMatch>();
  final AnalyzedTokenReadings[] tokens=text.getTokensWithoutWhitespace();
  if (speller == null) {
    if (JLanguageTool.getDataBroker().resourceExists(getFileName())) {
      speller=new MorfologikSpeller(getFileName(),conversionLocale);
    }
 else {
      return toRuleMatchArray(ruleMatches);
    }
  }
  skip:   for (  AnalyzedTokenReadings token : tokens) {
    if (isUrl(token.getToken())) {
      continue;
    }
    final String word=token.getToken();
    if (ignoreWord(word) || token.isImmunized()) {
      continue;
    }
    if (ignoreTaggedWords) {
      for (      AnalyzedToken at : token.getReadings()) {
        if (!at.hasNoTag()) {
          continue skip;
        }
      }
    }
    if (tokenizingPattern() == null) {
      ruleMatches.addAll(getRuleMatch(word,token.getStartPos()));
    }
 else {
      int index=0;
      final Matcher m=tokenizingPattern().matcher(word);
      while (m.find()) {
        final String match=word.subSequence(index,m.start()).toString();
        ruleMatches.addAll(getRuleMatch(match,token.getStartPos() + index));
        index=m.end();
      }
      if (index == 0) {
        ruleMatches.addAll(getRuleMatch(word,token.getStartPos()));
      }
 else {
        ruleMatches.addAll(getRuleMatch(word.subSequence(index,word.length()).toString(),token.getStartPos() + index));
      }
    }
  }
  return toRuleMatchArray(ruleMatches);
}
