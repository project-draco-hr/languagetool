{
  final List<RuleMatch> ruleMatches=new ArrayList<>();
  final AnalyzedTokenReadings[] tokens=sentence.getTokensWithoutWhitespace();
  if (speller == null) {
    if (JLanguageTool.getDataBroker().resourceExists(getFileName())) {
      speller=new MorfologikSpeller(getFileName(),MAX_EDIT_DISTANCE);
      setConvertsCase(speller.convertsCase());
    }
 else {
      return toRuleMatchArray(ruleMatches);
    }
  }
  int idx=-1;
  for (  AnalyzedTokenReadings token : tokens) {
    idx++;
    if (token.isSentenceStart()) {
      continue;
    }
    if (isUrl(token.getToken())) {
      continue;
    }
    if (ignoreToken(tokens,idx) || token.isImmunized() || token.isIgnoredBySpeller()) {
      continue;
    }
    if (ignoreTaggedWords && token.isTagged()) {
      continue;
    }
    final String word=token.getToken();
    if (tokenizingPattern() == null) {
      ruleMatches.addAll(getRuleMatches(word,token.getStartPos()));
    }
 else {
      int index=0;
      final Matcher m=tokenizingPattern().matcher(word);
      while (m.find()) {
        final String match=word.subSequence(index,m.start()).toString();
        ruleMatches.addAll(getRuleMatches(match,token.getStartPos() + index));
        index=m.end();
      }
      if (index == 0) {
        ruleMatches.addAll(getRuleMatches(word,token.getStartPos()));
      }
 else {
        ruleMatches.addAll(getRuleMatches(word.subSequence(index,word.length()).toString(),token.getStartPos() + index));
      }
    }
  }
  return toRuleMatchArray(ruleMatches);
}
