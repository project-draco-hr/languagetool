{
  List<AnalyzedToken> taggerTokens;
  List<AnalyzedToken> lowerTaggerTokens;
  List<AnalyzedToken> upperTaggerTokens;
  final List<AnalyzedTokenReadings> tokenReadings=new ArrayList<>();
  int pos=0;
  Matcher matcher;
  for (  String word : sentenceTokens) {
    String probeWord=word;
    for (; ; ) {
      final List<AnalyzedToken> l=new ArrayList<>();
      final String lowerWord=probeWord.toLowerCase(conversionLocale);
      taggerTokens=asAnalyzedTokenListForTaggedWords(word,getWordTagger().tag(probeWord));
      lowerTaggerTokens=asAnalyzedTokenListForTaggedWords(word,getWordTagger().tag(lowerWord));
      final boolean isLowercase=probeWord.equals(lowerWord);
      addTokens(taggerTokens,l);
      if (!isLowercase) {
        addTokens(lowerTaggerTokens,l);
      }
      if (lowerTaggerTokens.isEmpty() && taggerTokens.isEmpty()) {
        if (isLowercase) {
          upperTaggerTokens=asAnalyzedTokenListForTaggedWords(word,getWordTagger().tag(StringTools.uppercaseFirstChar(probeWord)));
          if (!upperTaggerTokens.isEmpty()) {
            addTokens(upperTaggerTokens,l);
          }
        }
        if (l.isEmpty()) {
          if ((matcher=patternSuffix.matcher(probeWord)).find()) {
            probeWord=matcher.group(1);
            continue;
          }
          l.add(new AnalyzedToken(word,null,null));
        }
      }
      tokenReadings.add(new AnalyzedTokenReadings(l,pos));
      pos+=word.length();
      break;
    }
  }
  return tokenReadings;
}
